{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import time\n",
    "from timeit import default_timer as timer\n",
    "from victor_thesis_experiments import *\n",
    "from victor_thesis_utils import *\n",
    "from victor_thesis_landscapes import *\n",
    "from victor_thesis_plots import *\n",
    "from victor_thesis_metrics import *\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from multiprocessing import cpu_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "from timeit import default_timer as timer\n",
    "from qnns.cuda_qnn import UnitaryParametrization\n",
    "#from victor_thesis_experiments import *\n",
    "from victor_thesis_utils import *\n",
    "from victor_thesis_landscapes import *\n",
    "from victor_thesis_plots import *\n",
    "from victor_thesis_metrics import *\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "# full experiment framework\n",
    "\n",
    "#todo\n",
    "def process_and_store_metrics(landscapes, conf_id):\n",
    "    #calculates and stores the raw metrics, the standard deviations and medians of the metrics and have config id in name of file to match to configs.txt\n",
    "    #gets 5 landscapes as input\n",
    "    #conf_id\n",
    "    #run_1\n",
    "    #TV=...\n",
    "    #...\n",
    "    #run_5\n",
    "    #...\n",
    "    #run_avg\n",
    "    #TV=...\n",
    "    #...\n",
    "    #run_stdv\n",
    "    #TV=...\n",
    "    #...\n",
    "    return 0\n",
    "\n",
    "#todo\n",
    "def store_configs_to_file(unitaries, configurations):\n",
    "    #write down all run configurations in a file with the run_ids\n",
    "    #-\n",
    "    #conf_id=16\n",
    "    #data_type=orthogonal\n",
    "    #num_data_points=3\n",
    "    #deg_entanglement=2\n",
    "    #unitary=[[a,b],[c,d]] (rough form)\n",
    "    #data_batch_1=[[...]]\n",
    "    #...\n",
    "    #data_batch_5=[[...]]\n",
    "    return 0\n",
    "\n",
    "#todo\n",
    "def generate_data_points(type_of_data, entanglement, num_data_points):\n",
    "    return type_of_data*entanglement*num_data_points\n",
    "\n",
    "# one asynchronous run will calculate 5 landscapes and their metrics\n",
    "def run_single_experiment(grid_size, dimensions, data_batch, U, qnn, conf_id):\n",
    "    #data batch contains 5 datapoint-sets, as we do 5 runs per unitary and then average etc.\n",
    "    landscapes= []\n",
    "    # for data_set in data_batch:\n",
    "    #     landscapes.append(generate_loss_landscape(grid_size, dimensions, data_set, U, qnn))\n",
    "    # process_and_store_metrics(landscapes, conf_id)\n",
    "    now = datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "    print(f\"[{now}] Finished run: {conf_id}\")\n",
    "\n",
    "def run_full_experiment(num_qubits, num_unitaries = 5, num_tries = 5):\n",
    "    # generate general qnn (?)\n",
    "    qnn = UnitaryParametrization(num_wires=num_qubits, num_layers=1, device='cpu')\n",
    "    grid_size = 2\n",
    "    dimensions = 2\n",
    "    unitaries = []\n",
    "    #[id_unitary][id_try][type_of_data][deg_of_entanglement][num_data_points]\n",
    "    configurations = []\n",
    "    for _ in range(num_unitaries):\n",
    "        #generate a random unitary with num_qubits qubits (why are they the same?)\n",
    "        unitaries.append(torch.tensor(np.array(random_unitary_matrix(num_qubits)), dtype=torch.complex128, device=\"cpu\"))\n",
    "\n",
    "    \n",
    "    start = time.time()\n",
    "    # generate configurations (5 datapoint sets = 5 runs per config)\n",
    "    conf_id = 0    \n",
    "    with ProcessPoolExecutor(cpu_count()) as exe:        \n",
    "        # iterate over  type of training data: 1=random, 2=orthogonal, 3=linearly dependent in H_x, 4= variable schmidt rank\n",
    "        for type_of_data in range(1,5,1):   \n",
    "            num_data_points_row = []\n",
    "            # iterate over degree of entanglement 1 to 4\n",
    "            for num_data_points in range(1,5,1):\n",
    "                deg_of_entanglement_row = []\n",
    "                # iterate over training data size 1 to 4\n",
    "                for deg_of_entanglement in range(1,5,1):\n",
    "                    # iterate over unitaries\n",
    "                    unitary_row = []\n",
    "                    for unitary in unitaries:       \n",
    "                        data_batch_for_unitary = []\n",
    "                        #iterate over number of tries/runs\n",
    "                        for _ in range(1,num_tries+1,1):\n",
    "                            # generate array of training data configurations [type_of_data][num_data_points][deg_of_entanglement][id_unitary][id_try]\n",
    "                            data_points = generate_data_points(type_of_data, deg_of_entanglement, num_data_points)\n",
    "                            data_batch_for_unitary.append(data_points)\n",
    "                        # run this per configuration unitary (5 sets of data -> take average and stdv...)\n",
    "                        exe.submit(run_single_experiment,grid_size, dimensions, data_batch_for_unitary, unitary, qnn, conf_id)                 \n",
    "                        conf_id += 1\n",
    "                        unitary_row.append(data_batch_for_unitary)                    \n",
    "                    deg_of_entanglement_row.append(unitary_row)\n",
    "                num_data_points_row.append(deg_of_entanglement_row)\n",
    "            configurations.append(num_data_points_row)\n",
    "\n",
    "    configurations = np.array(configurations)\n",
    "    print(configurations.shape)  \n",
    "    store_configs_to_file(unitaries, configurations)    \n",
    "    end = time.time()\n",
    "    print(f\"total runtime: {np.round(end-start,2)}s\")\n",
    "if __name__ == '__main__':\n",
    "    run_full_experiment(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test unitary parametrization\n",
    "num_qubits = 2\n",
    "qnn = UnitaryParametrization(num_wires=num_qubits, num_layers=1, device='cpu')\n",
    "random_unitary = torch.tensor(np.array(random_unitary_matrix(num_qubits)), dtype=torch.complex128, device=\"cpu\")\n",
    "print(\"qnn\",qnn.params)\n",
    "print(\"unitary\",random_unitary)\n",
    "non_entangled_inputs = generate_random_datapoints(55, num_qubits, random_unitary)\n",
    "non_entangled_landscape, _= generate_loss_landscape(15, 4 , non_entangled_inputs, random_unitary, qnn) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test n-dim landscape generation\n",
    "def test_ndim_landscapes():\n",
    "    # hadamard U2\n",
    "    qnn = get_qnn(\"CudaU2\", list(range(1)), 1, device=\"cpu\")\n",
    "    unitary = torch.tensor(np.array([[1, 1], [1, -1]]) / np.sqrt(2), dtype=torch.complex128, device=\"cpu\")\n",
    "    ############\n",
    "    # phase R\n",
    "    # qnn = get_qnn(\"CudaR\", list(range(1)), 1, device=\"cpu\")\n",
    "    # unitary = torch.tensor(np.array([[1, 0], [0, 1j]]), dtype=torch.complex128, device=\"cpu\")\n",
    "    ############\n",
    "    num_ticks = 100\n",
    "    data_points = 20\n",
    "    # generate data points\n",
    "    non_entangled_inputs = generate_random_datapoints(data_points, 1, unitary)\n",
    "    # print(\"starting small tests\")\n",
    "    # # actual 3d qnn vs 2d qnn with same tick number\n",
    "    # n_2d_ticks = 353\n",
    "    # start = timer()\n",
    "    # loss_nd, _ = generate_loss_landscape(n_2d_ticks,2, non_entangled_inputs, unitary, qnn)\n",
    "    # end = timer() \n",
    "    # print(f\"2d gen with* {n_2d_ticks**2} points: {np.round(end-start,3)}s\")\n",
    "\n",
    "    # qnn = get_qnn(\"CudaPennylane\", list(range(1)), 1, device=\"cpu\")\n",
    "    # n_3d_ticks = 50\n",
    "    # start = timer()\n",
    "    # loss_nd, _ = generate_loss_landscape(n_3d_ticks,3, non_entangled_inputs, unitary, qnn)\n",
    "    # end = timer() \n",
    "    # print(f\"3d gen with {n_3d_ticks**3} points: {np.round(end-start,3)}s\")\n",
    "\n",
    "    # multi dim and tick tests\n",
    "    qnn = get_qnn(\"CudaU2\", list(range(1)), 1, device=\"cpu\")\n",
    "    print(\"starting full tests\")\n",
    "    dimensions_tests = [2, 3, 4, 5, 6, 7, 8, 9]\n",
    "    num_ticks_tests = [3, 5, 7, 10, 15, 20]\n",
    "    for dimensions in dimensions_tests:\n",
    "        print(f\"{dimensions} PARAMS\")\n",
    "        for ticks in num_ticks_tests:    \n",
    "            start = timer()\n",
    "            landscape, _= generate_loss_landscape(ticks,dimensions, non_entangled_inputs, unitary, qnn)    \n",
    "            end = timer()        \n",
    "            print(f\"time for landscape generation with {dimensions} params and {ticks} ticks ({ticks**dimensions} points): {np.round(end-start,3)}s\")\n",
    "            start = timer()\n",
    "            calc_scalar_curvature(landscape)  \n",
    "            end = timer()        \n",
    "            print(f\"time for scalar curvature calculation: {np.round(end-start,3)}s\")\n",
    "            start = timer()\n",
    "            calc_total_variation(landscape)  \n",
    "            calc_IGSD(landscape)\n",
    "            calc_fourier_density(landscape) \n",
    "            end = timer()        \n",
    "            print(f\"time for all other metrics: {np.round(end-start,3)}s\")\n",
    "            print(\"-----\")\n",
    "        print(\"##############################################################################\")\n",
    "        print(\"##############################################################################\")\n",
    "        print(\"##############################################################################\")\n",
    "    #test 3d stuff\n",
    "test_ndim_landscapes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n-dim tests\n",
    "def n_dim_tests(\n",
    "):\n",
    "    qnn = get_qnn(\"CudaPennylane\", list(range(1)), 1, device=\"cpu\")\n",
    "    unitary = torch.tensor(\n",
    "        np.array([[1, 1], [1, -1]]) / np.sqrt(2), dtype=torch.complex128, device=\"cpu\"\n",
    "    )\n",
    "    num_ticks = 12\n",
    "    # generate data points\n",
    "    non_entangled_inputs = generate_random_datapoints(5, 1, unitary)\n",
    "    entangled_inputs = generate_random_datapoints(5, 2, unitary)\n",
    "    z_o_inputs = get_zero_one_datapoints()\n",
    "    # get 3d landscapes\n",
    "    loss_z_o_3d= generate_3D_loss_landscape(\n",
    "        num_ticks, z_o_inputs, unitary\n",
    "    )\n",
    "    loss_non_ent_3d= generate_3D_loss_landscape(\n",
    "        num_ticks, non_entangled_inputs, unitary\n",
    "    )\n",
    "    loss_ent_3d= generate_3D_loss_landscape(\n",
    "        num_ticks, entangled_inputs, unitary\n",
    "    )\n",
    "    landscapes = [loss_z_o_3d, loss_non_ent_3d, loss_ent_3d]\n",
    "    #test total variation\n",
    "    print(\n",
    "        \"TOTAL VARIATION: \",\n",
    "        calc_total_variation(landscapes[0]),\n",
    "        calc_total_variation(landscapes[1]),\n",
    "        calc_total_variation(landscapes[2]),\n",
    "    )\n",
    "    #test igsd\n",
    "    for landscape in landscapes:\n",
    "        igsd = calc_IGSD(landscape)\n",
    "        count = 1\n",
    "        for sd in igsd:\n",
    "            print(f\"IGSD (dir {count}): {sd}\")\n",
    "            count +=1\n",
    "        print(\"---------\")\n",
    "    #test fourier stuff\n",
    "    print(\"fourier densities:\")\n",
    "    print(calc_fourier_density(landscapes[0]))\n",
    "    print(calc_fourier_density(landscapes[1]))\n",
    "    print(calc_fourier_density(landscapes[2]))\n",
    "\n",
    "    #test scalar curvature\n",
    "    print(\"---------\")\n",
    "    print(\"Scalar curvature absolute sums: \")\n",
    "    for landscape in landscapes:\n",
    "        print(np.sum(np.absolute(calc_scalar_curvature(landscape))))\n",
    "    \n",
    "n_dim_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n-dim tests 2d\n",
    "qnn = get_qnn(\"CudaU2\", list(range(1)), 1, device=\"cpu\")\n",
    "unitary = torch.tensor(\n",
    "    np.array([[1, 1], [1, -1]]) / np.sqrt(2), dtype=torch.complex128, device=\"cpu\"\n",
    ")\n",
    "num_ticks = 12\n",
    "# generate data points\n",
    "non_entangled_inputs = generate_random_datapoints(5, 1, unitary)\n",
    "entangled_inputs = generate_random_datapoints(5, 2, unitary)\n",
    "z_o_inputs = get_zero_one_datapoints()\n",
    "# get 3d landscapes\n",
    "loss_z_o_3d= generate_2d_loss_landscape(\n",
    "    num_ticks, z_o_inputs, unitary, qnn\n",
    ")\n",
    "loss_non_ent_3d= generate_2d_loss_landscape(\n",
    "    num_ticks, non_entangled_inputs, unitary, qnn\n",
    ")\n",
    "loss_ent_3d= generate_2d_loss_landscape(\n",
    "    num_ticks, entangled_inputs, unitary, qnn\n",
    ")\n",
    "landscapes = [loss_z_o_3d, loss_non_ent_3d, loss_ent_3d]\n",
    "#test scalar curvature\n",
    "# print(get_scalar_curvature(landscapes[0]))\n",
    "# get_scalar_curvature(landscapes[1])\n",
    "# get_scalar_curvature(landscapes[2])\n",
    "#test total variation\n",
    "print(\n",
    "    \"TOTAL VARIATION: \",\n",
    "    calc_total_variation(landscapes[0]),\n",
    "    calc_total_variation(landscapes[1]),\n",
    "    calc_total_variation(landscapes[2]),\n",
    ")\n",
    "#test igsd\n",
    "for landscape in landscapes:\n",
    "    igsd = calc_IGSD(landscape)\n",
    "    count = 1\n",
    "    for sd in igsd:\n",
    "        print(f\"IGSD (dir {count}): {sd}\")\n",
    "        count +=1\n",
    "    print(\"---------\")\n",
    "#test fourier stuff\n",
    "print(\"fourier stuff\")\n",
    "fourier_landscape_z_o = get_fourier_landscape(z_o_inputs, unitary, qnn)\n",
    "fourier_landscape_non_entangled = get_fourier_landscape(non_entangled_inputs, unitary, qnn)\n",
    "fourier_landscape_entangled = get_fourier_landscape(entangled_inputs, unitary, qnn)\n",
    "print(calc_fourier_density(landscapes[0]))\n",
    "print(calc_fourier_density(landscapes[1]))\n",
    "print(calc_fourier_density(landscapes[2]))\n",
    "#test scalar curvature\n",
    "for landscape in landscapes:\n",
    "    print(\"SC: \",np.sum(np.absolute(calc_scalar_curvature(landscape))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fourier testing\n",
    "\n",
    "# hadamard U2\n",
    "qnn = get_qnn(\"CudaU2\", list(range(1)), 1, device=\"cpu\")\n",
    "unitary = torch.tensor(np.array([[1, 1], [1, -1]]) / np.sqrt(2), dtype=torch.complex128, device=\"cpu\")\n",
    "############\n",
    "# phase R\n",
    "# qnn = get_qnn(\"CudaR\", list(range(1)), 1, device=\"cpu\")\n",
    "# unitary = torch.tensor(np.array([[1, 0], [0, 1j]]), dtype=torch.complex128, device=\"cpu\")\n",
    "############\n",
    "num_ticks = 10\n",
    "# generate data points\n",
    "non_entangled_inputs = generate_random_datapoints(5, 1, unitary)\n",
    "entangled_inputs = generate_random_datapoints(5, 2, unitary)\n",
    "z_o_inputs = get_zero_one_datapoints()\n",
    "# get 2d landscapes\n",
    "loss_z_o= generate_2d_loss_landscape(\n",
    "    num_ticks, z_o_inputs, unitary, qnn\n",
    ")\n",
    "loss_non_ent= generate_2d_loss_landscape(\n",
    "    num_ticks, non_entangled_inputs, unitary, qnn\n",
    ")\n",
    "loss_ent= generate_2d_loss_landscape(\n",
    "    num_ticks, entangled_inputs, unitary, qnn\n",
    ")\n",
    "landscapes = [loss_z_o, loss_non_ent, loss_ent]\n",
    "\n",
    "#test fourier stuff\n",
    "print(\"fourier stuff\")\n",
    "fourier_landscape_z_o = get_fourier_landscape(z_o_inputs, unitary, qnn,num_ticks).values\n",
    "z_o_fd, z_o_f_plot = calc_fourier_density(landscapes[0])\n",
    "print(\"FD manual custom:\", z_o_fd)\n",
    "fourier_landscape_non_entangled = get_fourier_landscape(non_entangled_inputs, unitary, qnn,num_ticks).values\n",
    "n_e_fd, non_ent_f_plot = calc_fourier_density(landscapes[1])\n",
    "print(\"FD manual custom:\", n_e_fd)\n",
    "fourier_landscape_entangled = get_fourier_landscape(entangled_inputs, unitary, qnn,num_ticks).values\n",
    "e_fd, ent_f_plot = calc_fourier_density(landscapes[2])\n",
    "print(\"FD manual custom:\", e_fd)\n",
    "\n",
    "# differences possibly explained by different loss landscape sampling\n",
    "plot_row(landscapes, [\"zero one\", \"non ent\",\"entangled\"], \"Hadamard\", \"U2\", mode=\"default\")\n",
    "print(\"real values\")\n",
    "plot_fourier_row(np.absolute(np.array([fourier_landscape_z_o, fourier_landscape_non_entangled, fourier_landscape_entangled]).real), [\"zero one, with lib\", \"non entangled, with lib\",\"entangled, with lib\"])\n",
    "print(\"absolute sum: \", np.sum(np.absolute(np.array([fourier_landscape_z_o, fourier_landscape_non_entangled, fourier_landscape_entangled]).real)))\n",
    "plot_fourier_row(np.absolute(np.array([z_o_f_plot, non_ent_f_plot, ent_f_plot]).real), [\"zero one, manual\", \"non entangled, manual\",\"entangled, manual\"])\n",
    "print(\"absolute sum: \", np.sum(np.absolute(np.array([[z_o_f_plot, non_ent_f_plot, ent_f_plot]]).real)))\n",
    "\n",
    "print(\"imaginary values\")\n",
    "plot_fourier_row(np.absolute(np.array([fourier_landscape_z_o, fourier_landscape_non_entangled, fourier_landscape_entangled]).imag), [\"zero one, with lib\", \"non entangled, with lib\",\"entangled, with lib\"])\n",
    "print(\"absolute sum: \", np.sum(np.absolute(np.array([fourier_landscape_z_o, fourier_landscape_non_entangled, fourier_landscape_entangled]).imag)))\n",
    "plot_fourier_row(np.absolute(np.array([z_o_f_plot, non_ent_f_plot, ent_f_plot]).imag), [\"zero one, manual\", \"non entangled, manual\",\"entangled, manual\"])\n",
    "print(\"absolute sum: \", np.sum(np.absolute(np.array([[z_o_f_plot, non_ent_f_plot, ent_f_plot]]).imag)))\n",
    "\n",
    "print(\"sum of real and imaginary values\")\n",
    "plot_fourier_row(np.absolute(np.array([fourier_landscape_z_o, fourier_landscape_non_entangled, fourier_landscape_entangled]).imag)+np.absolute(np.array([fourier_landscape_z_o, fourier_landscape_non_entangled, fourier_landscape_entangled]).real), [\"zero one, with lib\", \"non entangled, with lib\",\"entangled, with lib\"])\n",
    "print(\"absolute sum: \", np.sum(np.absolute(np.array([fourier_landscape_z_o, fourier_landscape_non_entangled, fourier_landscape_entangled]).imag)+np.absolute(np.array([fourier_landscape_z_o, fourier_landscape_non_entangled, fourier_landscape_entangled]).real)))\n",
    "plot_fourier_row(np.absolute(np.array([z_o_f_plot, non_ent_f_plot, ent_f_plot]).imag)+np.absolute(np.array([z_o_f_plot, non_ent_f_plot, ent_f_plot]).real), [\"zero one, manual\", \"non entangled, manual\",\"entangled, manual\"])\n",
    "print(\"absolute sum: \", np.sum(np.absolute(np.array([[z_o_f_plot, non_ent_f_plot, ent_f_plot]]).imag)+np.absolute(np.array([[z_o_f_plot, non_ent_f_plot, ent_f_plot]]).real)))\n",
    "# print(calc_fourier_density(landscapes[0]))\n",
    "# print(calc_fourier_density(landscapes[1]))\n",
    "# print(calc_fourier_density(landscapes[2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXP on Hadamard\n",
    "run_hadamard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXP on Pauli-X\n",
    "run_pauli_x()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXP on Pauli-Y\n",
    "run_pauli_y()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXP on Pauli-Z\n",
    "run_pauli_z()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXP on Phase (S)\n",
    "run_phase_s()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "e6822839c80bb80c42f7f9e096efdd447a89633a8e8a553b5cfb2012f3a4eafe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

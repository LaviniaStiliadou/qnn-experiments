{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import time\n",
    "from timeit import default_timer as timer\n",
    "from victor_thesis_experiments_testing import *\n",
    "from victor_thesis_utils import *\n",
    "from victor_thesis_landscapes import *\n",
    "from victor_thesis_plots import *\n",
    "from victor_thesis_metrics import *\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from multiprocessing import cpu_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPERIMENT RESULTS HERE\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from victor_thesis_results_processing import *    \n",
    "\"\"\"loads and processes different results and combined results into text and plots that can be used for the final thesis or testing purposes\n",
    "    \"\"\"\n",
    "run_id = \"16_6_4_10_13_3_14\"\n",
    "datatype_labels = [\"random\", \"orthogonal\",\"average rank\",\"dependent\"]\n",
    "results, configs = get_results(run_id)\n",
    "#get data of all runs by schmidt rank\n",
    "combined_results_list = []\n",
    "combined_results_list.append(combine_results(get_results_where(results, configs, schmidt_rank=1)))\n",
    "combined_results_list.append(combine_results(get_results_where(results, configs, schmidt_rank=2)))\n",
    "combined_results_list.append(combine_results(get_results_where(results, configs, schmidt_rank=3)))\n",
    "combined_results_list.append(combine_results(get_results_where(results, configs, schmidt_rank=4)))\n",
    "visualize_metrics(combined_results_list, \"Schmidt Rank\", \"Mean and standard deviation of all metrics by Schmidt Rank \\n(over all data types)\")\n",
    "print_metrics(combined_results_list, \"type 1, by schmidt rank\")\n",
    "#get data of all runs except linearly dependent data by number of datapoints\n",
    "combined_results_list = []\n",
    "r1=[]\n",
    "r1+=get_results_where(results, configs, type_of_data=1, num_data_points=1)\n",
    "r1+=get_results_where(results, configs, type_of_data=2, num_data_points=1)\n",
    "r1+=get_results_where(results, configs, type_of_data=4, num_data_points=1)\n",
    "r2=[]\n",
    "r2+=get_results_where(results, configs, type_of_data=1, num_data_points=2)\n",
    "r2+=get_results_where(results, configs, type_of_data=2, num_data_points=2)\n",
    "r2+=get_results_where(results, configs, type_of_data=4, num_data_points=2)\n",
    "r3=[]\n",
    "r3+=get_results_where(results, configs, type_of_data=1, num_data_points=3)\n",
    "r3+=get_results_where(results, configs, type_of_data=2, num_data_points=3)\n",
    "r3+=get_results_where(results, configs, type_of_data=4, num_data_points=3)\n",
    "r4=[]\n",
    "r4+=get_results_where(results, configs, type_of_data=1, num_data_points=4)\n",
    "r4+=get_results_where(results, configs, type_of_data=2, num_data_points=4)\n",
    "r4+=get_results_where(results, configs, type_of_data=4, num_data_points=4)\n",
    "combined_results_list.append(combine_results(r1))\n",
    "combined_results_list.append(combine_results(r2))\n",
    "combined_results_list.append(combine_results(r3))\n",
    "combined_results_list.append(combine_results(r4))\n",
    "visualize_metrics(combined_results_list, \"Number Of Data Points\", \"Mean and standard deviation of all metrics by number of data points \\n(over all data types except linearly dependent data)\")\n",
    "print_metrics(combined_results_list, \"type 1, by schmidt rank\")\n",
    "#get data of linearly dependent data by number of datapoints\n",
    "combined_results_list = []\n",
    "combined_results_list.append(combine_results(get_results_where(results, configs, type_of_data=3, num_data_points=1)))\n",
    "combined_results_list.append(combine_results(get_results_where(results, configs, type_of_data=3, num_data_points=2)))\n",
    "combined_results_list.append(combine_results(get_results_where(results, configs, type_of_data=3, num_data_points=3)))\n",
    "combined_results_list.append(combine_results(get_results_where(results, configs, type_of_data=3, num_data_points=4)))\n",
    "visualize_metrics(combined_results_list, \"Number Of Data Points\", \"Mean and standard deviation of all metrics by number of data points \\n(over linearly dependent data only)\")\n",
    "print_metrics(combined_results_list, \"type 1, by schmidt rank\")\n",
    "#get data by datatype\n",
    "combined_results_list = []\n",
    "combined_results_list.append(combine_results(get_results_where(results, configs, type_of_data=1)))\n",
    "combined_results_list.append(combine_results(get_results_where(results, configs, type_of_data=2)))\n",
    "combined_results_list.append(combine_results(get_results_where(results, configs, type_of_data=4)))\n",
    "combined_results_list.append(combine_results(get_results_where(results, configs, type_of_data=3)))\n",
    "visualize_metrics(combined_results_list, \"type of data\", \"Mean and standard deviation of all metrics by type of data\", sample_labels=datatype_labels)\n",
    "print_metrics(combined_results_list, \"type 1, by schmidt rank\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CALCULATE METRIC DEVIATIONS\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from victor_thesis_results_processing import *\n",
    "\"\"\"cell used to calculate the colors for the table of the thesis\n",
    "\"\"\"\n",
    "run_id = \"16_6_4_10_13_3_14\"\n",
    "datatype_labels = [\"random\", \"orthogonal\",\"dependent\",\"average rank\"]\n",
    "results, configs = get_results(run_id)\n",
    "combined_results_list = []\n",
    "combined_results_list.append(combine_results(get_results_where(results, configs, type_of_data=1)))\n",
    "combined_results_list.append(combine_results(get_results_where(results, configs, type_of_data=2)))\n",
    "combined_results_list.append(combine_results(get_results_where(results, configs, type_of_data=3)))\n",
    "combined_results_list.append(combine_results(get_results_where(results, configs, type_of_data=4)))\n",
    "calculate_deviations(combined_results_list, datatype_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASIC LOSS LANDSCAPE FIGURE\n",
    "from datetime import datetime\n",
    "from torch import tensor\n",
    "from victor_thesis_results_processing import get_results\n",
    "from victor_thesis_utils import *\n",
    "from victor_thesis_landscapes import *\n",
    "from victor_thesis_plots import *\n",
    "from victor_thesis_metrics import *\n",
    "\"\"\"cell used to generate the basic loss landscape figure of the masters thesis paper\"\"\"\n",
    "run_id = \"10_6_3_26_14_44_31\" \n",
    "results, configs = get_results(run_id)\n",
    "\n",
    "def figure_basic_loss_landscape():\n",
    "    qnn = get_qnn(\"CudaU2\", list(range(1)), 1, device=\"cpu\")\n",
    "    U = torch.tensor(np.array([[1, 1], [1, -1]]) / np.sqrt(2), dtype=torch.complex128, device=\"cpu\")\n",
    "    #entangled_inputs = generate_random_datapoints(2, 1, U)\n",
    "    entangled_inputs= tensor([[[ 0.1076-0.5764j], [-0.7628+0.2727j]], [[ 0.2477+0.3764j], [-0.8891+0.0808j]]], dtype=torch.complex128)\n",
    "    print(entangled_inputs)\n",
    "    loss_ent = generate_2d_loss_landscape(50, entangled_inputs, U, qnn)\n",
    "    plot_3d_loss_landscape(\n",
    "        loss_ent, \"U2\", f\"Hadamard (on 2 data points)\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test unitary parametrization\n",
    "from qnns.cuda_qnn import CudaPennylane\n",
    "\n",
    "torch.set_num_threads(1)\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "\n",
    "num_qubits = 1\n",
    "qnn = CudaPennylane(num_wires=num_qubits, num_layers=2, device='cpu')\n",
    "random_unitary = torch.tensor(np.array(random_unitary_matrix(num_qubits)), dtype=torch.complex128, device=\"cpu\")\n",
    "print(\"tensor V\",qnn.get_tensor_V())\n",
    "print(\"params\",qnn.params)\n",
    "print(\"unitary\",random_unitary)\n",
    "non_entangled_inputs = generate_random_datapoints(3, num_qubits, random_unitary)\n",
    "non_entangled_landscape, _= generate_loss_landscape(3, 6 , non_entangled_inputs, random_unitary, qnn) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fourier testing\n",
    "\"\"\"cell used to test everything related to the fourier domain and fourier density\"\"\"\n",
    "# hadamard U2\n",
    "qnn = get_qnn(\"CudaU2\", list(range(1)), 1, device=\"cpu\")\n",
    "unitary = torch.tensor(np.array([[1, 1], [1, -1]]) / np.sqrt(2), dtype=torch.complex128, device=\"cpu\")\n",
    "############\n",
    "# phase R\n",
    "# qnn = get_qnn(\"CudaR\", list(range(1)), 1, device=\"cpu\")\n",
    "# unitary = torch.tensor(np.array([[1, 0], [0, 1j]]), dtype=torch.complex128, device=\"cpu\")\n",
    "############\n",
    "num_ticks = 4\n",
    "# generate data points\n",
    "non_entangled_inputs = generate_random_datapoints(5, 1, unitary)\n",
    "entangled_inputs = generate_random_datapoints(5, 2, unitary)\n",
    "z_o_inputs = get_zero_one_datapoints()\n",
    "# get 2d landscapes\n",
    "loss_z_o= generate_2d_loss_landscape(\n",
    "    num_ticks, z_o_inputs, unitary, qnn\n",
    ")\n",
    "loss_non_ent= generate_2d_loss_landscape(\n",
    "    num_ticks, non_entangled_inputs, unitary, qnn\n",
    ")\n",
    "loss_ent= generate_2d_loss_landscape(\n",
    "    num_ticks, entangled_inputs, unitary, qnn\n",
    ")\n",
    "landscapes = [loss_z_o, loss_non_ent, loss_ent]\n",
    "\n",
    "#test fourier stuff\n",
    "print(\"fourier stuff\")\n",
    "fourier_landscape_z_o = get_fourier_landscape(z_o_inputs, unitary, qnn,num_ticks).values\n",
    "z_o_fd, z_o_f_plot = calc_fourier_density(landscapes[0])\n",
    "print(\"FD manual custom:\", z_o_fd)\n",
    "fourier_landscape_non_entangled = get_fourier_landscape(non_entangled_inputs, unitary, qnn,num_ticks).values\n",
    "n_e_fd, non_ent_f_plot = calc_fourier_density(landscapes[1])\n",
    "print(\"FD manual custom:\", n_e_fd)\n",
    "fourier_landscape_entangled = get_fourier_landscape(entangled_inputs, unitary, qnn,num_ticks).values\n",
    "e_fd, ent_f_plot = calc_fourier_density(landscapes[2])\n",
    "print(\"FD manual custom:\", e_fd)\n",
    "\n",
    "# differences possibly explained by different loss landscape sampling\n",
    "plot_row(landscapes, [\"zero one\", \"non ent\",\"entangled\"], \"Hadamard\", \"U2\", mode=\"default\")\n",
    "print(\"real values\")\n",
    "plot_fourier_row(np.absolute(np.array([fourier_landscape_z_o, fourier_landscape_non_entangled, fourier_landscape_entangled]).real), [\"zero one, with lib\", \"non entangled, with lib\",\"entangled, with lib\"])\n",
    "print(\"absolute sum: \", np.sum(np.absolute(np.array([fourier_landscape_z_o, fourier_landscape_non_entangled, fourier_landscape_entangled]).real)))\n",
    "plot_fourier_row(np.absolute(np.array([z_o_f_plot, non_ent_f_plot, ent_f_plot]).real), [\"zero one, manual\", \"non entangled, manual\",\"entangled, manual\"])\n",
    "print(\"absolute sum: \", np.sum(np.absolute(np.array([[z_o_f_plot, non_ent_f_plot, ent_f_plot]]).real)))\n",
    "\n",
    "print(\"imaginary values\")\n",
    "plot_fourier_row(np.absolute(np.array([fourier_landscape_z_o, fourier_landscape_non_entangled, fourier_landscape_entangled]).imag), [\"zero one, with lib\", \"non entangled, with lib\",\"entangled, with lib\"])\n",
    "print(\"absolute sum: \", np.sum(np.absolute(np.array([fourier_landscape_z_o, fourier_landscape_non_entangled, fourier_landscape_entangled]).imag)))\n",
    "plot_fourier_row(np.absolute(np.array([z_o_f_plot, non_ent_f_plot, ent_f_plot]).imag), [\"zero one, manual\", \"non entangled, manual\",\"entangled, manual\"])\n",
    "print(\"absolute sum: \", np.sum(np.absolute(np.array([[z_o_f_plot, non_ent_f_plot, ent_f_plot]]).imag)))\n",
    "\n",
    "print(\"sum of real and imaginary values\")\n",
    "plot_fourier_row(np.absolute(np.array([fourier_landscape_z_o, fourier_landscape_non_entangled, fourier_landscape_entangled]).imag)+np.absolute(np.array([fourier_landscape_z_o, fourier_landscape_non_entangled, fourier_landscape_entangled]).real), [\"zero one, with lib\", \"non entangled, with lib\",\"entangled, with lib\"])\n",
    "print(\"absolute sum: \", np.sum(np.absolute(np.array([fourier_landscape_z_o, fourier_landscape_non_entangled, fourier_landscape_entangled]).imag)+np.absolute(np.array([fourier_landscape_z_o, fourier_landscape_non_entangled, fourier_landscape_entangled]).real)))\n",
    "plot_fourier_row(np.absolute(np.array([z_o_f_plot, non_ent_f_plot, ent_f_plot]).imag)+np.absolute(np.array([z_o_f_plot, non_ent_f_plot, ent_f_plot]).real), [\"zero one, manual\", \"non entangled, manual\",\"entangled, manual\"])\n",
    "print(\"absolute sum: \", np.sum(np.absolute(np.array([[z_o_f_plot, non_ent_f_plot, ent_f_plot]]).imag)+np.absolute(np.array([[z_o_f_plot, non_ent_f_plot, ent_f_plot]]).real)))\n",
    "# print(calc_fourier_density(landscapes[0]))\n",
    "# print(calc_fourier_density(landscapes[1]))\n",
    "# print(calc_fourier_density(landscapes[2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXP on Hadamard\n",
    "run_hadamard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXP on Pauli-X\n",
    "run_pauli_x()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXP on Pauli-Y\n",
    "run_pauli_y()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXP on Pauli-Z\n",
    "run_pauli_z()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXP on Phase (S)\n",
    "run_phase_s()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "e6822839c80bb80c42f7f9e096efdd447a89633a8e8a553b5cfb2012f3a4eafe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

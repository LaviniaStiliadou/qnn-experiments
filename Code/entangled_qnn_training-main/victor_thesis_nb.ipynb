{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "from mpl_toolkits.axes_grid1 import AxesGrid\n",
    "import orqviz\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from classic_training import cost_func\n",
    "from data import *\n",
    "from generate_experiments import get_qnn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib\n",
    "import matplotlib as mpl\n",
    "import qnns.cuda_qnn as cuda_qnn\n",
    "from utils import *\n",
    "from matplotlib import cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gen datapoints\n",
    "def generate_random_datapoints(numb_points, s_rank, U):\n",
    "    schmidt_rank = s_rank\n",
    "    num_points = numb_points\n",
    "    x_qbits = 1\n",
    "    r_qbits = s_rank - x_qbits\n",
    "    inputs = torch.from_numpy(\n",
    "        np.array(uniform_random_data(schmidt_rank, num_points, x_qbits, r_qbits))\n",
    "    )\n",
    "    inputs = inputs.reshape(\n",
    "        (inputs.shape[0], int(inputs.shape[1] / U.shape[0]), U.shape[0])\n",
    "    ).permute(0, 2, 1)\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get zero/one datapoints\n",
    "def get_zero_one_datapoints():\n",
    "    zero_state = np.array([[1],[0]], dtype=complex)\n",
    "    one_state = np.array([[0],[1]], dtype=complex)\n",
    "    super_pos_state = np.array([[1],[1]], dtype=complex)/np.sqrt(2)\n",
    "    tensor = torch.tensor([zero_state, one_state])\n",
    "    return tensor\n",
    "    # inputs = torch.from_numpy(np.array([zero_state, one_state], dtype=complex))\n",
    "    # print(inputs.size())\n",
    "    # inputs = inputs.reshape((inputs.shape[0], int(inputs.shape[1] / U.shape[0]), U.shape[0])).permute(0, 2, 1)\n",
    "    # return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gen 2D loss landscape\n",
    "def generate_loss_landscape(grid_size, inputs, U, qnn):\n",
    "    landscape = []\n",
    "    lanscape_limit = 2 * math.pi\n",
    "    step_size = lanscape_limit / grid_size\n",
    "    x = inputs\n",
    "    expected_output = torch.matmul(U, x)\n",
    "    y_true = expected_output.conj()\n",
    "    for i in range(grid_size):\n",
    "        # start at 2pi so y axis label still fits (upwards scaling instead of downards)\n",
    "        arg_1 = lanscape_limit - i * step_size\n",
    "        row = []\n",
    "        for j in range(grid_size):\n",
    "            # start at 0 because x axis label direction is correct\n",
    "            arg_2 = j * step_size\n",
    "            qnn.params = torch.tensor([[[arg_1, arg_2]]], dtype=torch.float64, requires_grad=True)\n",
    "            cost = cost_func(inputs, y_true, qnn, device=\"cpu\")\n",
    "            row.append(cost.item())\n",
    "        landscape.append(row)\n",
    "    return landscape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gen 3D loss landscape for U3\n",
    "def generate_3D_loss_landscape_with_labels(grid_size, inputs, U):\n",
    "    qnn = get_qnn(\"CudaPennylane\", list(range(1)), 1, device=\"cpu\")\n",
    "    landscape = []\n",
    "    x_array =[]\n",
    "    y_array = []\n",
    "    z_array = []\n",
    "    points = []\n",
    "    lanscape_limit = 2 * math.pi\n",
    "    step_size = lanscape_limit / grid_size\n",
    "    x = inputs\n",
    "    expected_output = torch.matmul(U, x)\n",
    "    y_true = expected_output.conj()\n",
    "    for i in range(grid_size):\n",
    "        # start at 2pi so y axis label still fits (upwards scaling instead of downards)\n",
    "        arg_1 = i * step_size\n",
    "        for j in range(grid_size):\n",
    "            # start at 0 because x axis label direction is correct\n",
    "            arg_2 = lanscape_limit-j * step_size\n",
    "            for k in range(grid_size):\n",
    "                # maybe change direction?\n",
    "                arg_3 = k * step_size\n",
    "                qnn.params = torch.tensor([[[arg_1, arg_2, arg_3]]], dtype=torch.float64, requires_grad=True)\n",
    "                cost = cost_func(inputs, y_true, qnn, device=\"cpu\")\n",
    "                landscape.append(cost.item())\n",
    "                x_array.append(arg_3)\n",
    "                y_array.append(arg_2)\n",
    "                z_array.append(arg_1)\n",
    "    points.append(x_array)\n",
    "    points.append(y_array)\n",
    "    points.append(z_array)\n",
    "    return landscape, points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get plot metadata for different modes\n",
    "def get_meta_for_mode(mode, data, min_val, max_val,titles,o, gate_name, ansatz):\n",
    "    low_threshold= 0.000000001\n",
    "    if mode ==\"default\":\n",
    "        c_map =\"plasma\"\n",
    "        sup_title= f\"Loss Landscapes for {ansatz}($\\\\phi,\\\\lambda)$ Approximating {gate_name} for Different Datasets\"\n",
    "        title=titles[o]\n",
    "        v_min = min(min_val, 0)\n",
    "        v_max = max(max_val,1)\n",
    "    elif mode == \"grad\":\n",
    "        c_map =\"winter\"\n",
    "        sup_title= \"Gradient Magnitudes\"\n",
    "        # average gradient magnitude adjusted for sample frequency - not sure how to call this.\n",
    "        title= f\"GM Score: {np.round(np.average(data)*len(data), 2)}\"\n",
    "        v_min = min(min_val, 0)\n",
    "        v_max = math.ceil(max_val * 100.0) / 100.0\n",
    "    elif mode == \"log_scale\":\n",
    "        v_max = 1\n",
    "        #v_min = min((min_val+low_threshold/18)*12, low_threshold)\n",
    "        v_min = low_threshold\n",
    "        c_map =\"Greys\"\n",
    "        if min_val < low_threshold:\n",
    "            min_text=\"< 0.000000001\"\n",
    "        else:\n",
    "            min_text=f\"= {np.round(min_val, 10)}\"        \n",
    "        sup_title= f\"Logarithmic Loss (min. {min_text})\"\n",
    "        title= titles[o]\n",
    "    return c_map, sup_title, title, v_min, v_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a row of datasets\n",
    "def plot_row(in_data,titles, gate_name, ansatz, mode=\"default\"):    \n",
    "    in_data\n",
    "    width = len(in_data)        \n",
    "    min_val = np.min(in_data)\n",
    "    max_val = np.max(in_data)\n",
    "    fig, ax = plt.subplots(1, width, figsize=(9,3))\n",
    "    for data_idx in range(width):        \n",
    "        data = in_data[data_idx]\n",
    "        # get mode dependent settings such as titles, color maps, thresholds, etc.\n",
    "        c_map, sup_title, title, v_min, v_max = get_meta_for_mode(mode, data, min_val, max_val, titles, data_idx, gate_name, ansatz)\n",
    "        length = len(data)\n",
    "        x_labels = []\n",
    "        # create labels\n",
    "        for i in range(length):\n",
    "            n = f\"{np.round(i*2/length, 1)} $\\\\pi$\"\n",
    "            x_labels.append(n)\n",
    "        y_labels = reversed(x_labels)\n",
    "        # do plot stuff\n",
    "        # for logarithmic scale\n",
    "        if mode == \"log_scale\":\n",
    "            data = data + v_min\n",
    "            im = ax[data_idx].imshow(data, cmap = c_map,norm=matplotlib.colors.LogNorm(vmin=v_min, vmax=v_max))\n",
    "        else:\n",
    "        # normal scale\n",
    "            im = ax[data_idx].imshow(data, cmap = c_map,vmin=v_min, vmax=v_max)\n",
    "        # what happens to values below the color bar (=legend) threshold\n",
    "        cm_copy= im.cmap.copy()\n",
    "        cm_copy.set_under(\"r\", 1)\n",
    "        im.cmap = cm_copy\n",
    "        # set label ticks\n",
    "        ax[data_idx].set_xticks(np.arange(len(x_labels)), labels=x_labels)\n",
    "        ax[data_idx].set_yticks(np.arange(len(x_labels)), labels=y_labels)\n",
    "        ax[data_idx].set_ylabel(\"$\\\\phi$\", rotation= 180, va=\"center\")\n",
    "        ax[data_idx].set_xlabel(\"$\\\\lambda$\")\n",
    "        tick_density = int(length / 4)\n",
    "        # only display every x'th tick\n",
    "        ax[data_idx].set_xticks(ax[data_idx].get_xticks()[::tick_density])\n",
    "        ax[data_idx].set_yticks(ax[data_idx].get_yticks()[::tick_density])\n",
    "        plt.setp(ax[data_idx].get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "\n",
    "        ax[data_idx].set_title(title)\n",
    "    fig.colorbar(im, ax=ax.ravel().tolist(), shrink=0.58)\n",
    "    plt.subplots_adjust(left=0.1,\n",
    "                    bottom=0.1, \n",
    "                    right=0.75, \n",
    "                    top=0.9, \n",
    "                    wspace=0.7)\n",
    "    fig.suptitle(sup_title, x=0.43)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D scatter plot of U3 Gate\n",
    "def plot_scatter_of_U3(landscape, points, ticks):\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    ax = fig.add_subplot(projection='3d')    \n",
    "    v_min = 0.000000001\n",
    "    v_max = 1\n",
    "    values = np.array(landscape)+v_min\n",
    "    # the higher v_min, the more similar entangled and non entangled sample minima look\n",
    "\n",
    "\n",
    "    x = points[0]\n",
    "    y = points[1]\n",
    "    z = points[2]\n",
    "    c_white = matplotlib.colors.colorConverter.to_rgba('white',alpha = 0)\n",
    "    c_red= matplotlib.colors.colorConverter.to_rgba('red',alpha = 1)\n",
    "    cmap_rb = matplotlib.colors.LinearSegmentedColormap.from_list('rb_cmap',[c_red,c_white],512)\n",
    "\n",
    "    im = ax.scatter(x,y,z, c=values, cmap = cmap_rb,norm=matplotlib.colors.LogNorm(vmin=v_min,vmax=v_max)\n",
    ", depthshade=0)\n",
    "    # set labels\n",
    "    length = 6\n",
    "    x_labels = []\n",
    "    # create labels\n",
    "    for i in range(length+1):\n",
    "        n = f\"{np.round(i*2/length,1)} $\\\\pi$\"\n",
    "        x_labels.append(n)\n",
    "    x_labels = x_labels\n",
    "    y_labels = x_labels\n",
    "    z_labels = x_labels # just for fun\n",
    "    # set label ticks\n",
    "    #labels not really working\n",
    "    tick_density = int(length / 5)\n",
    "    ax.set_xticks(np.arange(len(x_labels)), labels=x_labels)\n",
    "    ax.set_yticks(np.arange(len(x_labels)), labels=y_labels)\n",
    "    ax.set_zticks(np.arange(len(x_labels)), labels=z_labels)\n",
    "    # ax.set_xticks(ax.get_xticks()[::tick_density])\n",
    "    # ax.set_yticks(ax.get_yticks()[::tick_density])\n",
    "    # ax.set_zticks(ax.get_zticks()[::tick_density])\n",
    "    ax.set_ylabel(\"$\\\\phi$\", rotation= 180, va=\"center\")\n",
    "    ax.set_xlabel(\"$\\\\lambda$\")\n",
    "    ax.set_zlabel(\"der andere parameter\")\n",
    "    # only display every x'th tick\n",
    "\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "    ax.set_title(f\"U3 Minima for (finish title later)\")\n",
    "    # set colorbar\n",
    "    cbar = ax.figure.colorbar(im, ax=ax)\n",
    "    cbar.ax.set_ylabel(\"Loss\", rotation=-90, va=\"bottom\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot 3D loss landscape\n",
    "# https://matplotlib.org/stable/gallery/images_contours_and_fields/image_annotated_heatmap.html\n",
    "def plot_3d_loss_landscape(landscape, ansatz,title):\n",
    "    ls = np.array(landscape)\n",
    "    min_val = np.min(ls)\n",
    "    max_val = np.max(ls)\n",
    "    length = len(ls)\n",
    "    x_labels = []\n",
    "    # create labels\n",
    "    for i in range(length):\n",
    "        n = f\"{np.round(i*2/length,1)} $\\\\pi$\"\n",
    "        x_labels.append(n)\n",
    "    y_labels = reversed(x_labels)\n",
    "    fig, ax = plt.subplots(subplot_kw={\"projection\": \"3d\"})\n",
    "    #im = ax.imshow(ls, cmap = \"plasma\",vmin=min(min_val, 0), vmax=max(max_val,1))\n",
    "    X = np.arange(0, length,1)\n",
    "    Y = np.arange(0, length,1)\n",
    "    X, Y = np.meshgrid(X, Y)\n",
    "    im = ax.plot_surface(X,Y,ls, cmap = \"plasma\",vmin=min(min_val, 0), vmax=max(max_val,1))\n",
    "    # set label ticks\n",
    "    ax.set_xticks(np.arange(len(x_labels)), labels=x_labels)\n",
    "    ax.set_yticks(np.arange(len(x_labels)), labels=y_labels)\n",
    "    ax.set_ylabel(\"$\\\\phi$\", rotation= 180, va=\"center\")\n",
    "    ax.set_xlabel(\"$\\\\lambda$\")\n",
    "    ax.set_zlabel(\"Loss\")\n",
    "    tick_density = int(length / 10)\n",
    "    # only display every x'th tick\n",
    "    ax.set_xticks(ax.get_xticks()[::tick_density])\n",
    "    ax.set_yticks(ax.get_yticks()[::tick_density])\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "    cbar = ax.figure.colorbar(im, ax=ax)\n",
    "    cbar.ax.set_ylabel(\"Loss\", rotation=-90, va=\"bottom\")\n",
    "    ax.set_title(f\"{ansatz}($\\\\phi,\\\\lambda)$ Approximating {title}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get grad curvature\n",
    "def get_grad_curv(landscape):\n",
    "    first_order_gradients = np.gradient(np.array(landscape))\n",
    "    second_order_gradients = []\n",
    "    for grad in first_order_gradients:\n",
    "        grads_of_grad = np.gradient(np.array(grad))\n",
    "        for sec_grad in grads_of_grad:\n",
    "            second_order_gradients.append(sec_grad)\n",
    "    magnitude_sum = 0\n",
    "    for g in second_order_gradients:\n",
    "        magnitude_sum += g**2\n",
    "    curv_mag = np.sqrt(magnitude_sum)\n",
    "    return curv_mag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get scalar curvature\n",
    "def get_scalar_curvature(landscape):\n",
    "    grad_xx_xy_yx_yy = []\n",
    "    scalar_curvature = []\n",
    "    gradients = np.array(np.gradient(np.array(landscape)))\n",
    "    # maybe add gradients? not sure\n",
    "    for gradient in gradients:\n",
    "        second_grads = np.array(np.gradient(np.array(gradient)))\n",
    "        for second_grad in second_grads:\n",
    "            grad_xx_xy_yx_yy.append(second_grad)\n",
    "    # calculate scalar curvature point by point\n",
    "    for x_id in range(len(landscape)):\n",
    "        row = []\n",
    "        for y_id in range(len(landscape)):\n",
    "            # hessian for point with entries: [d_xx, d_xy][d_yx, d_yy]\n",
    "            point_hessian = [[grad_xx_xy_yx_yy[0][x_id][y_id], grad_xx_xy_yx_yy[1][x_id][y_id]],[grad_xx_xy_yx_yy[2][x_id][y_id], grad_xx_xy_yx_yy[3][x_id][y_id]]]\n",
    "            # gradients as 2 entry vector (x dir, y dir)\n",
    "            gradient = np.array([gradients[1][x_id][y_id],gradients[0][x_id][y_id]])\n",
    "            # take euclidean norm\n",
    "            beta = 1/(1+np.linalg.norm(gradient)**2)\n",
    "            left_term = beta*(np.trace(point_hessian)**2-np.trace(np.matmul(point_hessian, point_hessian)))\n",
    "            right_inner = np.matmul(point_hessian, point_hessian)-np.trace(point_hessian)*np.array(point_hessian)\n",
    "            # order of matmul with gradient does not matter\n",
    "            right_term= 2*(beta**2)*(np.matmul(np.matmul(gradient.T,right_inner),gradient))\n",
    "            point_curv = left_term + right_term\n",
    "            #print(point_curv)\n",
    "            #maybe sum, maybe not? point curv is 2 entry vector\n",
    "            row.append(point_curv)\n",
    "        scalar_curvature.append(row) \n",
    "        # output absolute and root to compare visually to grad curvature\n",
    "    return scalar_curvature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot 3D loss landscape with curvature coloring\n",
    "def plot_3d_loss_landscape_curv(landscape, ansatz, curv_mode = \"scalar\"):\n",
    "    landscape = np.array(landscape)\n",
    "    if curv_mode == \"scalar\":        \n",
    "        curv = get_scalar_curvature(landscape)\n",
    "    elif curv_mode == \"grad\":\n",
    "        curv = get_grad_curv(landscape)\n",
    "    #normalize from -1 to 1\n",
    "    # max_entry = np.max(np.absolute(curv))\n",
    "    # curv = curv/max_entry\n",
    "    min_val = np.min(curv)\n",
    "    max_val = np.max(curv)\n",
    "    length = len(curv)\n",
    "    x_labels = []\n",
    "    # create labels\n",
    "    for i in range(length):\n",
    "        n = f\"{np.round(i*2/length,1)} $\\\\pi$\"\n",
    "        x_labels.append(n)\n",
    "    y_labels = reversed(x_labels)\n",
    "    fig, ax = plt.subplots(subplot_kw={\"projection\": \"3d\"})\n",
    "    X = np.arange(0, length,1)\n",
    "    Y = np.arange(0, length,1)\n",
    "    X, Y = np.meshgrid(X, Y)\n",
    "    norm = mpl.colors.Normalize(vmin=min_val, vmax=max_val)\n",
    "    c_map = mpl.cm.plasma\n",
    "    im = ax.plot_surface(X,Y,landscape, cmap = c_map, facecolors = c_map(norm(curv)))\n",
    "    # set label ticks\n",
    "    ax.set_xticks(np.arange(len(x_labels)), labels=x_labels)\n",
    "    ax.set_yticks(np.arange(len(x_labels)), labels=y_labels)\n",
    "    ax.set_ylabel(\"$\\\\phi$\", rotation= 180, va=\"center\")\n",
    "    ax.set_xlabel(\"$\\\\lambda$\")\n",
    "    ax.set_zlabel(\"Loss\")\n",
    "    tick_density = int(length / 10)\n",
    "    # only display every x'th tick\n",
    "    ax.set_xticks(ax.get_xticks()[::tick_density])\n",
    "    ax.set_yticks(ax.get_yticks()[::tick_density])\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "    #cbar = ax.figure.colorbar(im, ax=ax)\n",
    "    #cbar.ax.set_ylabel(\"Loss\", rotation=-90, va=\"bottom\")\n",
    "    m = cm.ScalarMappable(cmap=c_map, norm=norm)\n",
    "    m.set_array([])\n",
    "    plt.colorbar(m)\n",
    "    ax.set_title(f\"{ansatz}($\\\\phi,\\\\lambda)$ Curvature - {curv_mode} curvature\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate Total Variation\n",
    "def calc_total_variation(landscape):\n",
    "    lanscape_limit = 2 * math.pi\n",
    "    step_size = lanscape_limit / len(landscape)\n",
    "    gradients = np.gradient(np.array(landscape))\n",
    "    total_variation = np.sum(np.absolute(gradients))\n",
    "    # normalize by adjusting for step size\n",
    "    normalized_tv = total_variation*step_size\n",
    "    return np.round(normalized_tv,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate IGSD\n",
    "def calc_IGSD(landscape):\n",
    "    gradients = np.gradient(np.array(landscape))\n",
    "    # each array of the gradients encompasses the gradients for one dimension/direction/parameter\n",
    "    gradient_standard_deviations = []\n",
    "    for gradient in gradients:\n",
    "        gradient_standard_deviations.append(np.std(gradient))\n",
    "    inverse_gradient_standard_deviations= np.divide(1,gradient_standard_deviations)\n",
    "    return np.round(inverse_gradient_standard_deviations,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi plot with gradients\n",
    "def multi_plot_landscape(landscapes, titles, gate_name, ansatz): \n",
    "    data = np.array(landscapes)\n",
    "    # calculate gradient magnitudes\n",
    "    gradient_magnitudes=[]\n",
    "    for landscape_idx in range(len(data)):\n",
    "        gradient = np.gradient(np.array(landscapes[landscape_idx]))\n",
    "        grad_mag = np.sqrt(gradient[0]**2+gradient[1]**2)\n",
    "        gradient_magnitudes.append(grad_mag)\n",
    "    # Plot rows for each mode you want to display\n",
    "    plot_row(data, titles,gate_name, ansatz, mode=\"default\")\n",
    "    plot_row(data, titles,gate_name, ansatz, mode=\"log_scale\")\n",
    "    plot_row(gradient_magnitudes, ansatz, titles, gate_name, mode=\"grad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print expected output\n",
    "def print_expected_output(U, x, name):\n",
    "    print(\"====\")\n",
    "    expected_output = torch.matmul(U,x)\n",
    "    np_arr = expected_output.detach().cpu().numpy()\n",
    "    print(\"expected output for \",name,\":\\n\",np_arr)\n",
    "    print(\"====\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print datapoints\n",
    "def print_datapoints(points, title):\n",
    "    print(\"\", title, \" data points:\")\n",
    "    np_arr = points.detach().cpu().numpy()\n",
    "    for i, row in enumerate(np_arr):\n",
    "        print(\"---\")\n",
    "        for j, point in enumerate(row):\n",
    "            #idx = i * len(row) + j + 1\n",
    "            print(\"\",i,\" - \", j, \":\", point)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get fourier landscape\n",
    "def get_fourier_landscape(inputs, U, qnn):\n",
    "    def loss_function(params):\n",
    "        qnn.params = torch.tensor([[[params[0], params[1]]]], dtype=torch.float64, requires_grad=True)\n",
    "        x = inputs\n",
    "        expected_output = torch.matmul(U, x)\n",
    "        y_true = expected_output.conj()\n",
    "        return cost_func(x, y_true, qnn, device=\"cpu\")\n",
    "    n_params = 2\n",
    "    params = np.random.uniform(-np.pi, np.pi, size=n_params)\n",
    "    dir1 = np.array([0.0, 1.0])\n",
    "    dir2 = np.array([1.0, 0.0])\n",
    "    end_points = (0, 2 * np.pi)\n",
    "    fourier_result = orqviz.fourier.scan_2D_fourier(\n",
    "        params,\n",
    "        loss_function,\n",
    "        direction_x=dir1,\n",
    "        direction_y=dir2,\n",
    "        n_steps_x=60,\n",
    "        end_points_x=end_points,\n",
    "    )\n",
    "    fourier_density = round(np.linalg.norm(np.array(fourier_result.values), ord=1)**2 / np.linalg.norm(np.array(fourier_result.values), ord=2)**2,3)\n",
    "    print(\"Fourier Density:\",fourier_density)\n",
    "    return fourier_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiments Framework\n",
    "def run_experiment_on(gate_name, unitary, ansatz, print_info = True, num_data_points=1, num_ticks = 20, fourier_plot =1):\n",
    "    qnn = get_qnn(\"Cuda\"+ansatz, list(range(1)), 1, device=\"cpu\")\n",
    "    # generate data points\n",
    "    non_entangled_inputs = generate_random_datapoints(num_data_points, 1, unitary)\n",
    "    entangled_inputs = generate_random_datapoints(num_data_points,2,unitary)\n",
    "    z_o_inputs = get_zero_one_datapoints()\n",
    "    if print_info:\n",
    "        # print data points\n",
    "        print_datapoints(z_o_inputs, \"zero-one\")\n",
    "        print_datapoints(non_entangled_inputs, \"not entangled\")\n",
    "        print_datapoints(entangled_inputs, \"entangled\")\n",
    "        #print expected output\n",
    "        print_expected_output(unitary, z_o_inputs, \"zero one\")\n",
    "    # calculate loss landscapes\n",
    "    loss_z_o = generate_loss_landscape(num_ticks, z_o_inputs, unitary, qnn)\n",
    "    loss_non_ent = generate_loss_landscape(num_ticks, non_entangled_inputs, unitary, qnn)\n",
    "    loss_ent = generate_loss_landscape(num_ticks, entangled_inputs, unitary, qnn)\n",
    "    # multiplot lanscapes and gradients    \n",
    "    landscapes = [loss_z_o,loss_non_ent, loss_ent]\n",
    "    names = [f\"Zero-One, n = 2\",f\"Not Entangled, n = {num_data_points}\", f\"Entangled, n = {num_data_points}\"]\n",
    "    multi_plot_landscape(landscapes, names, gate_name, ansatz)    \n",
    "    # print advanced metrics    \n",
    "    print(\"TOTAL VARIATION: \",calc_total_variation(landscapes[0]),calc_total_variation(landscapes[1]),calc_total_variation(landscapes[2]))\n",
    "    for landscape in landscapes:\n",
    "        igsd = calc_IGSD(landscape)\n",
    "        print(\"IGSD (dir 1): \", igsd[0])\n",
    "        print(\"IGSD (dir 2): \", igsd[1])\n",
    "        print(\"---------\")\n",
    "    # fourier stuff -> enable only 1 at a time\n",
    "    print(\"Frequency Domain for Plot\", fourier_plot)\n",
    "    if fourier_plot == 1:\n",
    "        fourier_result_z_o = get_fourier_landscape(z_o_inputs, unitary, qnn)\n",
    "        orqviz.fourier.plot_2D_fourier_result(fourier_result_z_o, max_freq_x=10, max_freq_y=10)\n",
    "    elif fourier_plot == 2:\n",
    "        fourier_result_non_ent = get_fourier_landscape(non_entangled_inputs, unitary, qnn)\n",
    "        orqviz.fourier.plot_2D_fourier_result(fourier_result_non_ent, max_freq_x=10, max_freq_y=10)\n",
    "    elif fourier_plot == 3:\n",
    "        fourier_result_ent = get_fourier_landscape(entangled_inputs, unitary, qnn)\n",
    "        orqviz.fourier.plot_2D_fourier_result(fourier_result_ent, max_freq_x=10, max_freq_y=10)\n",
    "    # U3 scatter plots\n",
    "    loss_z_o_3d, points_z_o = generate_3D_loss_landscape_with_labels(num_ticks, z_o_inputs, unitary)\n",
    "    loss_non_ent_3d, points_non_ent = generate_3D_loss_landscape_with_labels(num_ticks, non_entangled_inputs, unitary)\n",
    "    loss_ent_3d, points_ent = generate_3D_loss_landscape_with_labels(num_ticks, entangled_inputs, unitary)\n",
    "    plot_scatter_of_U3(loss_z_o_3d, points_z_o, num_ticks)\n",
    "    plot_scatter_of_U3(loss_non_ent_3d, points_non_ent, num_ticks)\n",
    "    plot_scatter_of_U3(loss_ent_3d, points_ent, num_ticks)\n",
    "    # plot loss landscapes\n",
    "    plot_3d_loss_landscape(loss_z_o, ansatz, f\"{gate_name} (Zero-One, n = 2)\")\n",
    "    plot_3d_loss_landscape(loss_non_ent, ansatz, f\"{gate_name} (Not Entangled, n = {num_data_points})\")\n",
    "    plot_3d_loss_landscape(loss_ent, ansatz, f\"{gate_name} (Entangled, n = {num_data_points})\")\n",
    "    # with curvature coloring placeholder\n",
    "    plot_3d_loss_landscape_curv(loss_z_o, ansatz,\"scalar\")\n",
    "    plot_3d_loss_landscape_curv(loss_z_o, ansatz,\"grad\")\n",
    "    plot_3d_loss_landscape_curv(loss_non_ent, ansatz,\"scalar\")\n",
    "    plot_3d_loss_landscape_curv(loss_non_ent, ansatz,\"grad\")\n",
    "    plot_3d_loss_landscape_curv(loss_ent, ansatz,\"scalar\")\n",
    "    plot_3d_loss_landscape_curv(loss_ent, ansatz,\"grad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXP on Hadamard\n",
    "U = torch.tensor(np.array([[1, 1], [1, -1]]) / np.sqrt(2), dtype=torch.complex128, device=\"cpu\")\n",
    "run_experiment_on(\"Hadamard\", U, ansatz = \"U2\", print_info=False, num_data_points=1, num_ticks = 20, fourier_plot=3)\n",
    "# U3 visualization has troubles with different tick numbers -> maybe sample errors? \n",
    "# red dots on logarithmic loss are true minima (below a certain threshold), sometimes they are just above the threshold but still true minima (due to sampling) and they will appear white (not grey, as grey means they are false minima)\n",
    "# if num_ticks is too large you cant see the red dots anymore (maybe due to aliasing?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXP on Pauli-X\n",
    "U = torch.tensor(np.array([[0, 1], [1, 0]]), dtype=torch.complex128, device=\"cpu\")\n",
    "run_experiment_on(\"Pauli-X\", U, ansatz = \"R\", print_info=False, num_data_points=1, num_ticks = 20, fourier_plot=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXP on Pauli-Y\n",
    "U = torch.tensor(np.array([[0, -1j], [1j, 0]]), dtype=torch.complex128, device=\"cpu\")\n",
    "run_experiment_on(\"Pauli-Y\", U, ansatz = \"U2\", print_info=False, num_data_points=11, num_ticks = 20, fourier_plot=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXP on Pauli-Z\n",
    "U = torch.tensor(np.array([[1, 0], [0, -1]]), dtype=torch.complex128, device=\"cpu\")\n",
    "run_experiment_on(\"Pauli-Z\", U, ansatz = \"U2\", print_info=False, num_data_points=11, num_ticks = 20, fourier_plot=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXP on Phase (S)\n",
    "U = torch.tensor(np.array([[1, 0], [0, 1j]]), dtype=torch.complex128, device=\"cpu\")\n",
    "run_experiment_on(\"Phase-S\", U, ansatz = \"U2\", print_info=False, num_data_points=1, num_ticks = 20, fourier_plot=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
